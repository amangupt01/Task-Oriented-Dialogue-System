{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFOTiqrtNvyy"
      },
      "source": [
        "# Install Transformers Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pratyush/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "\n",
        "# specify GPU\n",
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKd-Tj3hOMsZ"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Send_digital_object': 0,\n",
              " 'Get_health_stats': 1,\n",
              " 'Get_message_content': 2,\n",
              " 'Add_contact': 3,\n",
              " 'Initiate_call': 4,\n",
              " 'Create_note': 5,\n",
              " 'Add_item_to_list': 6,\n",
              " 'Create_list': 7,\n",
              " 'Get_list': 8,\n",
              " 'Order_menu_item': 9,\n",
              " 'Find_parking': 10,\n",
              " 'Get_note': 11,\n",
              " 'Start_exercise': 12,\n",
              " 'Stop_exercise': 13,\n",
              " 'Resume_exercise': 14,\n",
              " 'Pause_exercise': 15,\n",
              " 'Log_exercise': 16,\n",
              " 'Log_nutrition': 17,\n",
              " 'Check_order_status': 18,\n",
              " 'Get_bill': 19,\n",
              " 'Get_security_price': 20,\n",
              " 'Open_app': 21,\n",
              " 'Pay_bill': 22,\n",
              " 'Get_product': 23,\n",
              " 'Other': 24,\n",
              " 'Post_message': 25,\n",
              " 'Record_video': 26,\n",
              " 'Take_photo': 27,\n",
              " 'Cancel_ride': 28,\n",
              " 'Order_ride': 29,\n",
              " 'BuyEventTickets': 30,\n",
              " 'Play_game': 31,\n",
              " 'GetGenericBusinessType': 32}"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import jsonlines\n",
        "intent_dict = {}\n",
        "intent_counter = 0\n",
        "with jsonlines.open('data/train.jsonl') as reader: \n",
        "    for obj in reader: \n",
        "        output_raw = obj['output'] \n",
        "        intent = output_raw.split(' ')[0]\n",
        "        if intent not in intent_dict:\n",
        "            intent_dict[intent] = intent_counter\n",
        "            intent_counter += 1\n",
        "intent_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(intent_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dataset(file_path):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    with jsonlines.open(file_path) as reader: \n",
        "        for obj in reader: \n",
        "            input_raw = obj['input'] \n",
        "            output_raw = obj['output'] \n",
        "            intent = output_raw.split(' ')[0]\n",
        "            texts.append(input_raw)\n",
        "            labels.append(intent_dict[intent])\n",
        "    # make labels as class int\n",
        "    labels = np.array(labels, dtype=np.int64)\n",
        "    return pd.DataFrame({'text': texts, 'label': labels})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train = create_dataset('data/train.jsonl')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_train.to_csv('data/train.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(30993, 2)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "24    7729\n",
              "4     1245\n",
              "0     1106\n",
              "6      977\n",
              "15     914\n",
              "3      909\n",
              "18     886\n",
              "13     884\n",
              "12     879\n",
              "31     846\n",
              "26     819\n",
              "16     814\n",
              "11     807\n",
              "25     792\n",
              "32     788\n",
              "1      776\n",
              "30     773\n",
              "27     771\n",
              "21     738\n",
              "19     722\n",
              "17     715\n",
              "20     703\n",
              "22     695\n",
              "23     689\n",
              "28     682\n",
              "29     674\n",
              "2      611\n",
              "5      585\n",
              "14     458\n",
              "7      287\n",
              "9      269\n",
              "10     262\n",
              "8      188\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_train['label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cwJrQFQgN_BE",
        "outputId": "854f0b55-e330-4806-cc32-79643e6bd721"
      },
      "outputs": [],
      "source": [
        "# df = pd.read_csv(\"spamdata_v2.csv\")\n",
        "# df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "fzPPOrVQWiW5",
        "outputId": "e8555c2b-a50d-4809-833f-adf3ac349a1b"
      },
      "outputs": [],
      "source": [
        "# df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "676DPU1BOPdp",
        "outputId": "075808af-7b2e-4f0d-e888-e06e2e8abbf9"
      },
      "outputs": [],
      "source": [
        "# # check class distribution\n",
        "# df['label'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mfhSPF5jOWb7"
      },
      "outputs": [],
      "source": [
        "# train_text, temp_text, train_labels, temp_labels = train_test_split(df['text'], df['label'], \n",
        "#                                                                     random_state=2018, \n",
        "#                                                                     test_size=0.3, \n",
        "#                                                                     stratify=df['label'])\n",
        "\n",
        "# # we will use temp_text and temp_labels to create validation and test set\n",
        "# val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
        "#                                                                 random_state=2018, \n",
        "#                                                                 test_size=0.5, \n",
        "#                                                                 stratify=temp_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_text = df_train['text']\n",
        "train_labels = df_train['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_val = create_dataset('data/dev.jsonl')\n",
        "val_text = df_val['text']\n",
        "val_labels = df_val['label']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# train_labels = [int(i) for i in train_labels]\n",
        "# val_labels = [int(i) for i in val_labels]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7hsdLoCO7uB"
      },
      "source": [
        "# Import BERT Model and BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164,
          "referenced_widgets": [
            "983fea7c2dc74dfaba7aa60147af85d1",
            "ccf5f7e5cc10493ca9c44b14fdec31dc",
            "59bae99ad63d4a3a8b8d622d95f7ad07",
            "689e66a8dff249449b5f0f5bbfffa037",
            "49dd79a9a65044ba8345deb250ce4b24",
            "47862cd626cf46619a5cc505fde02276",
            "cb5f7a2a5bcb47649703cc633f2fb685",
            "6d2355752eb74f348596a380d2347b73",
            "0e580433bec2453da54c0ce9ee027401",
            "bdfd7634b8bf42aa8794ada8d9e47173",
            "73fc7587f1bb49df8a0fc87ecfac7f3c",
            "4da1c15300b2468ab1a7e2df800ed39b",
            "645d520e8a1c4f1fa202c6c68c5ce6af",
            "3bb6b624b4ce4be788c38cb8d1936177",
            "ed9f97f9d12a49aa939b7595ad3cb27c",
            "88214abee8b9462f86369072d858ae9f",
            "b4bef5a685954e238b52c43eefe4c9e5",
            "94264f36ceb64d3881fed952bf579072",
            "8cf06dad410440f78c50e3527e858905",
            "edf0e4c1ae214a66abb717b20e3bffad",
            "4d56a47453914de3be15d7a515e5b210",
            "6831c2b733d74b31a41cb6eb971a25d7",
            "58cd585c531444a5b8613c2d85bab022",
            "b6423c858927455e8cbc5a953273466a"
          ]
        },
        "id": "S1kY3gZjO2RE",
        "outputId": "4194574c-05d6-4d1d-c4c0-8dd89913ff79"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "# import BERT-base pretrained model\n",
        "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "outputs": [],
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "oAH73n39PHLw",
        "outputId": "17b76300-71f2-464c-90b0-a5907f4f675a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'input_ids': [[101, 2023, 2003, 1037, 14324, 2944, 14924, 4818, 102, 0], [101, 2057, 2097, 2986, 1011, 8694, 1037, 14324, 2944, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ],
      "source": [
        "# output\n",
        "print(sent_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wIYaWI_Prg8"
      },
      "source": [
        "# Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "yKwbpeN_PMiu",
        "outputId": "9f843240-6cf4-46c9-80b7-dc9ab4e03602"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "29"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get length of all the messages in the train set\n",
        "seq_len = [len(i.split()) for i in train_text]\n",
        "# print(seq_len)\n",
        "# plot distribution of sequence length\n",
        "max(seq_len)\n",
        "# pd.Series(seq_len).hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "outputs": [],
      "source": [
        "max_seq_len = 60"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "tk5S7DWaP2t6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/pratyush/.local/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2323: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False,\n",
        "    return_tensors='pt'\n",
        ")\n",
        "\n",
        "# # tokenize and encode sequences in the test set\n",
        "# tokens_test = tokenizer.batch_encode_plus(\n",
        "#     test_text.tolist(),\n",
        "#     max_length = max_seq_len,\n",
        "#     pad_to_max_length=True,\n",
        "#     truncation=True,\n",
        "#     return_token_type_ids=False\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wsm8bkRZQTw9"
      },
      "source": [
        "# Convert Integer Sequences to Tensors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_614157/1772564847.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_seq = torch.tensor(tokens_train['input_ids'], dtype=torch.long)\n",
            "/tmp/ipykernel_614157/1772564847.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  train_mask = torch.tensor(tokens_train['attention_mask'], dtype=torch.long)\n",
            "/tmp/ipykernel_614157/1772564847.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_seq = torch.tensor(tokens_val['input_ids'], dtype=torch.long)\n",
            "/tmp/ipykernel_614157/1772564847.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  val_mask = torch.tensor(tokens_val['attention_mask'], dtype=torch.long)\n"
          ]
        }
      ],
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'], dtype=torch.long)\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'], dtype=torch.long)\n",
        "train_y = torch.tensor(train_labels.tolist(), dtype=torch.long)\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'], dtype=torch.long)\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'], dtype=torch.long)\n",
        "val_y = torch.tensor(val_labels.tolist(), dtype=torch.long)\n",
        "\n",
        "# # for test set\n",
        "# test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "# test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "# test_y = torch.tensor(test_labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop,\n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ov1cOBlcRLuk"
      },
      "source": [
        "# Create DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "qUy9JKFYQYLp"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "#define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# wrap tensors\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# dataLoader for train set\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "# wrap tensors\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "\n",
        "# sampler for sampling the data during training\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "\n",
        "# dataLoader for validation set\n",
        "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "outputs": [],
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,33)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "outputs": [],
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model = model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "taXS0IilRn9J"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-04-15 00:17:22.735488: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-04-15 00:17:23.604024: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pratyush/.local/lib/python3.10/site-packages/\n",
            "2023-04-15 00:17:23.604135: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/pratyush/.local/lib/python3.10/site-packages/\n",
            "2023-04-15 00:17:23.604148: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
            "/home/pratyush/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer = AdamW(model.parameters(), lr = 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "izY5xH5eR7Ur",
        "outputId": "4682d190-bf40-4824-89af-91983ae6b174"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.84916982 1.21028585 1.53712245 1.03320332 0.75436291 1.60543901\n",
            " 0.96129152 3.27241052 4.99564797 3.49138222 3.58466343 1.16379407\n",
            " 1.06846623 1.06242287 2.05061532 1.02755122 1.15378602 1.313541\n",
            " 1.06002463 1.30080584 1.33596276 1.27260409 1.35134075 1.36310859\n",
            " 0.12151401 1.18583563 1.14674215 1.21813465 1.37709944 1.39344483\n",
            " 1.21498295 1.11014399 1.1918551 ]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight='balanced', classes = np.unique(train_labels),y= train_labels)\n",
        "\n",
        "print(class_wts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "outputs": [],
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "outputs": [],
      "source": [
        "# function to train the model\n",
        "def train():\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "    # print(sent_id[0][0], mask[0][0], labels[0])\n",
        "    # print(type(sent_id), type(mask), type(labels))\n",
        "    # print(sent_id.shape, mask.shape, labels.shape)\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(val_dataloader):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      # elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(val_dataloader) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k1USGTntS3TS",
        "outputId": "6c03e17f-476c-4741-eae5-c5722cb5d413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Epoch 1 / 10\n",
            "  Batch    50  of    969.\n",
            "  Batch   100  of    969.\n",
            "  Batch   150  of    969.\n",
            "  Batch   200  of    969.\n",
            "  Batch   250  of    969.\n",
            "  Batch   300  of    969.\n",
            "  Batch   350  of    969.\n",
            "  Batch   400  of    969.\n",
            "  Batch   450  of    969.\n",
            "  Batch   500  of    969.\n",
            "  Batch   550  of    969.\n",
            "  Batch   600  of    969.\n",
            "  Batch   650  of    969.\n",
            "  Batch   700  of    969.\n",
            "  Batch   750  of    969.\n",
            "  Batch   800  of    969.\n",
            "  Batch   850  of    969.\n",
            "  Batch   900  of    969.\n",
            "  Batch   950  of    969.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    290.\n",
            "  Batch   100  of    290.\n",
            "  Batch   150  of    290.\n",
            "  Batch   200  of    290.\n",
            "  Batch   250  of    290.\n",
            "\n",
            "Training Loss: 2.573\n",
            "Validation Loss: 2.204\n",
            "\n",
            " Epoch 2 / 10\n",
            "  Batch    50  of    969.\n",
            "  Batch   100  of    969.\n",
            "  Batch   150  of    969.\n",
            "  Batch   200  of    969.\n",
            "  Batch   250  of    969.\n",
            "  Batch   300  of    969.\n",
            "  Batch   350  of    969.\n",
            "  Batch   400  of    969.\n",
            "  Batch   450  of    969.\n",
            "  Batch   500  of    969.\n",
            "  Batch   550  of    969.\n",
            "  Batch   600  of    969.\n",
            "  Batch   650  of    969.\n",
            "  Batch   700  of    969.\n",
            "  Batch   750  of    969.\n",
            "  Batch   800  of    969.\n",
            "  Batch   850  of    969.\n",
            "  Batch   900  of    969.\n",
            "  Batch   950  of    969.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    290.\n",
            "  Batch   100  of    290.\n",
            "  Batch   150  of    290.\n",
            "  Batch   200  of    290.\n",
            "  Batch   250  of    290.\n",
            "\n",
            "Training Loss: 2.113\n",
            "Validation Loss: 1.832\n",
            "\n",
            " Epoch 3 / 10\n",
            "  Batch    50  of    969.\n",
            "  Batch   100  of    969.\n",
            "  Batch   150  of    969.\n",
            "  Batch   200  of    969.\n",
            "  Batch   250  of    969.\n",
            "  Batch   300  of    969.\n",
            "  Batch   350  of    969.\n",
            "  Batch   400  of    969.\n",
            "  Batch   450  of    969.\n",
            "  Batch   500  of    969.\n",
            "  Batch   550  of    969.\n",
            "  Batch   600  of    969.\n",
            "  Batch   650  of    969.\n",
            "  Batch   700  of    969.\n",
            "  Batch   750  of    969.\n",
            "  Batch   800  of    969.\n",
            "  Batch   850  of    969.\n",
            "  Batch   900  of    969.\n",
            "  Batch   950  of    969.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    290.\n",
            "  Batch   100  of    290.\n",
            "  Batch   150  of    290.\n",
            "  Batch   200  of    290.\n",
            "  Batch   250  of    290.\n",
            "\n",
            "Training Loss: 1.851\n",
            "Validation Loss: 1.727\n",
            "\n",
            " Epoch 4 / 10\n",
            "  Batch    50  of    969.\n",
            "  Batch   100  of    969.\n",
            "  Batch   150  of    969.\n",
            "  Batch   200  of    969.\n",
            "  Batch   250  of    969.\n",
            "  Batch   300  of    969.\n",
            "  Batch   350  of    969.\n",
            "  Batch   400  of    969.\n",
            "  Batch   450  of    969.\n",
            "  Batch   500  of    969.\n",
            "  Batch   550  of    969.\n",
            "  Batch   600  of    969.\n",
            "  Batch   650  of    969.\n",
            "  Batch   700  of    969.\n",
            "  Batch   750  of    969.\n",
            "  Batch   800  of    969.\n",
            "  Batch   850  of    969.\n",
            "  Batch   900  of    969.\n",
            "  Batch   950  of    969.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    290.\n",
            "  Batch   100  of    290.\n",
            "  Batch   150  of    290.\n",
            "  Batch   200  of    290.\n",
            "  Batch   250  of    290.\n",
            "\n",
            "Training Loss: 1.689\n",
            "Validation Loss: 1.708\n",
            "\n",
            " Epoch 5 / 10\n",
            "  Batch    50  of    969.\n",
            "  Batch   100  of    969.\n",
            "  Batch   150  of    969.\n",
            "  Batch   200  of    969.\n",
            "  Batch   250  of    969.\n",
            "  Batch   300  of    969.\n",
            "  Batch   350  of    969.\n",
            "  Batch   400  of    969.\n",
            "  Batch   450  of    969.\n",
            "  Batch   500  of    969.\n",
            "  Batch   550  of    969.\n",
            "  Batch   600  of    969.\n",
            "  Batch   650  of    969.\n",
            "  Batch   700  of    969.\n",
            "  Batch   750  of    969.\n",
            "  Batch   800  of    969.\n",
            "  Batch   850  of    969.\n",
            "  Batch   900  of    969.\n",
            "  Batch   950  of    969.\n",
            "\n",
            "Evaluating...\n",
            "  Batch    50  of    290.\n",
            "  Batch   100  of    290.\n",
            "  Batch   150  of    290.\n",
            "  Batch   200  of    290.\n",
            "  Batch   250  of    290.\n",
            "\n",
            "Training Loss: 1.568\n",
            "Validation Loss: 1.551\n",
            "\n",
            " Epoch 6 / 10\n",
            "  Batch    50  of    969.\n",
            "  Batch   100  of    969.\n",
            "  Batch   150  of    969.\n",
            "  Batch   200  of    969.\n",
            "  Batch   250  of    969.\n",
            "  Batch   300  of    969.\n",
            "  Batch   350  of    969.\n",
            "  Batch   400  of    969.\n",
            "  Batch   450  of    969.\n",
            "  Batch   500  of    969.\n",
            "  Batch   550  of    969.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[35], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m Epoch \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m / \u001b[39m\u001b[39m{:}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, epochs))\n\u001b[1;32m     13\u001b[0m \u001b[39m#train model\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m train_loss, _ \u001b[39m=\u001b[39m train()\n\u001b[1;32m     16\u001b[0m \u001b[39m#evaluate model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m valid_loss, _ \u001b[39m=\u001b[39m evaluate()\n",
            "Cell \u001b[0;32mIn[31], line 45\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mclip_grad_norm_(model\u001b[39m.\u001b[39mparameters(), \u001b[39m1.0\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[39m# update parameters\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     47\u001b[0m \u001b[39m# model predictions are stored on GPU. So, push it to CPU\u001b[39;00m\n\u001b[1;32m     48\u001b[0m preds\u001b[39m=\u001b[39mpreds\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/optim/optimizer.py:140\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    139\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 140\u001b[0m     out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    141\u001b[0m     obj\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/optimization.py:362\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    360\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m(\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta1))\n\u001b[1;32m    361\u001b[0m exp_avg_sq\u001b[39m.\u001b[39mmul_(beta2)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1.0\u001b[39m \u001b[39m-\u001b[39m beta2)\n\u001b[0;32m--> 362\u001b[0m denom \u001b[39m=\u001b[39m exp_avg_sq\u001b[39m.\u001b[39;49msqrt()\u001b[39m.\u001b[39;49madd_(group[\u001b[39m\"\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    364\u001b[0m step_size \u001b[39m=\u001b[39m group[\u001b[39m\"\u001b[39m\u001b[39mlr\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m group[\u001b[39m\"\u001b[39m\u001b[39mcorrect_bias\u001b[39m\u001b[39m\"\u001b[39m]:  \u001b[39m# No bias correction for Bert\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, _ = train()\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, _ = evaluate()\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "OacxUyizS8d1",
        "outputId": "c8b951c2-1f74-4a13-db65-8acd077995e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "# clear cuda cache\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Batch    50  of    290.\n",
            "  Batch   100  of    290.\n",
            "  Batch   150  of    290.\n",
            "  Batch   200  of    290.\n",
            "  Batch   250  of    290.\n"
          ]
        }
      ],
      "source": [
        "# get predictions for test data\n",
        "predictions = []\n",
        "for step,batch in enumerate(val_dataloader):\n",
        "  \n",
        "  # Progress update every 50 batches.\n",
        "  if step % 50 == 0 and not step == 0:\n",
        "    \n",
        "    # Calculate elapsed time in minutes.\n",
        "    # elapsed = format_time(time.time() - t0)\n",
        "          \n",
        "    # Report progress.\n",
        "    print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
        "\n",
        "  # push the batch to gpu\n",
        "  batch = [t.to(device) for t in batch]\n",
        "\n",
        "  sent_id, mask, labels = batch\n",
        "\n",
        "  # deactivate autograd\n",
        "  with torch.no_grad():\n",
        "    \n",
        "    # model predictions\n",
        "    preds = model(sent_id, mask)\n",
        "    preds = preds.detach().cpu().numpy()\n",
        "  predictions.append(preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [],
      "source": [
        "predictions  = np.concatenate(predictions, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "Ms1ObHZxTYSI",
        "outputId": "47d01595-e519-4a58-8f2e-75596ea1512d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.37      0.40      0.39       331\n",
            "           1       0.61      0.66      0.64       232\n",
            "           2       0.45      0.57      0.50       182\n",
            "           3       0.41      0.79      0.54       272\n",
            "           4       0.45      0.45      0.45       373\n",
            "           5       0.23      0.44      0.30       174\n",
            "           6       0.29      0.58      0.38       292\n",
            "           7       0.12      0.29      0.17        86\n",
            "           8       0.22      0.25      0.23        56\n",
            "           9       0.39      0.51      0.44        79\n",
            "          10       0.32      0.69      0.43        78\n",
            "          11       0.40      0.50      0.44       242\n",
            "          12       0.34      0.39      0.36       263\n",
            "          13       0.52      0.50      0.51       264\n",
            "          14       0.20      0.74      0.31       137\n",
            "          15       0.56      0.38      0.45       273\n",
            "          16       0.34      0.62      0.44       243\n",
            "          17       0.43      0.63      0.51       214\n",
            "          18       0.63      0.51      0.56       265\n",
            "          19       0.50      0.64      0.56       216\n",
            "          20       0.56      0.35      0.43       211\n",
            "          21       0.56      0.42      0.48       220\n",
            "          22       0.59      0.83      0.69       207\n",
            "          23       0.49      0.47      0.48       206\n",
            "          24       0.88      0.14      0.24      2318\n",
            "          25       0.40      0.77      0.53       237\n",
            "          26       0.61      0.73      0.67       245\n",
            "          27       0.63      0.55      0.59       230\n",
            "          28       0.44      0.78      0.57       204\n",
            "          29       0.64      0.42      0.50       202\n",
            "          30       0.67      0.87      0.76       231\n",
            "          31       0.55      0.48      0.52       253\n",
            "          32       0.68      0.44      0.53       236\n",
            "\n",
            "    accuracy                           0.45      9272\n",
            "   macro avg       0.47      0.54      0.47      9272\n",
            "weighted avg       0.58      0.45      0.43      9272\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# model's performance\n",
        "preds = np.argmax(predictions, axis = 1)\n",
        "print(classification_report(val_y, preds))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "YqzLS7rHTp4T",
        "outputId": "d3abc432-5ad0-41e5-cfc2-d1d1192f5672"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>col_0</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>row_0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>710</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "col_0    0    1\n",
              "row_0          \n",
              "0      710   14\n",
              "1        9  103"
            ]
          },
          "execution_count": 27,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jpX1uTwjUPY6"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Fine-Tuning BERT for Spam Classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0e580433bec2453da54c0ce9ee027401": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_73fc7587f1bb49df8a0fc87ecfac7f3c",
              "IPY_MODEL_4da1c15300b2468ab1a7e2df800ed39b"
            ],
            "layout": "IPY_MODEL_bdfd7634b8bf42aa8794ada8d9e47173"
          }
        },
        "3bb6b624b4ce4be788c38cb8d1936177": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47862cd626cf46619a5cc505fde02276": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49dd79a9a65044ba8345deb250ce4b24": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "4d56a47453914de3be15d7a515e5b210": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "4da1c15300b2468ab1a7e2df800ed39b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88214abee8b9462f86369072d858ae9f",
            "placeholder": "​",
            "style": "IPY_MODEL_ed9f97f9d12a49aa939b7595ad3cb27c",
            "value": " 440M/440M [00:11&lt;00:00, 37.5MB/s]"
          }
        },
        "58cd585c531444a5b8613c2d85bab022": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59bae99ad63d4a3a8b8d622d95f7ad07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47862cd626cf46619a5cc505fde02276",
            "max": 433,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_49dd79a9a65044ba8345deb250ce4b24",
            "value": 433
          }
        },
        "645d520e8a1c4f1fa202c6c68c5ce6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": "initial"
          }
        },
        "6831c2b733d74b31a41cb6eb971a25d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689e66a8dff249449b5f0f5bbfffa037": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d2355752eb74f348596a380d2347b73",
            "placeholder": "​",
            "style": "IPY_MODEL_cb5f7a2a5bcb47649703cc633f2fb685",
            "value": " 433/433 [00:00&lt;00:00, 1.98kB/s]"
          }
        },
        "6d2355752eb74f348596a380d2347b73": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73fc7587f1bb49df8a0fc87ecfac7f3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3bb6b624b4ce4be788c38cb8d1936177",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_645d520e8a1c4f1fa202c6c68c5ce6af",
            "value": 440473133
          }
        },
        "88214abee8b9462f86369072d858ae9f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf06dad410440f78c50e3527e858905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "Downloading: 100%",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6831c2b733d74b31a41cb6eb971a25d7",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d56a47453914de3be15d7a515e5b210",
            "value": 231508
          }
        },
        "94264f36ceb64d3881fed952bf579072": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "983fea7c2dc74dfaba7aa60147af85d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59bae99ad63d4a3a8b8d622d95f7ad07",
              "IPY_MODEL_689e66a8dff249449b5f0f5bbfffa037"
            ],
            "layout": "IPY_MODEL_ccf5f7e5cc10493ca9c44b14fdec31dc"
          }
        },
        "b4bef5a685954e238b52c43eefe4c9e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cf06dad410440f78c50e3527e858905",
              "IPY_MODEL_edf0e4c1ae214a66abb717b20e3bffad"
            ],
            "layout": "IPY_MODEL_94264f36ceb64d3881fed952bf579072"
          }
        },
        "b6423c858927455e8cbc5a953273466a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdfd7634b8bf42aa8794ada8d9e47173": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb5f7a2a5bcb47649703cc633f2fb685": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccf5f7e5cc10493ca9c44b14fdec31dc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed9f97f9d12a49aa939b7595ad3cb27c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "edf0e4c1ae214a66abb717b20e3bffad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6423c858927455e8cbc5a953273466a",
            "placeholder": "​",
            "style": "IPY_MODEL_58cd585c531444a5b8613c2d85bab022",
            "value": " 232k/232k [00:39&lt;00:00, 5.82kB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
